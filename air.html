<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@500&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@500&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="air.css">
    <link rel="icon" href="https://vitap.ac.in/wp-content/uploads/2020/07/cropped-logo_icon-1-32x32.png" sizes="32x32">
    <title>VIT-AP – Apply Knowledge. Improve Life!</title>
</head>

<body>
    <nav class="navbar navbar-expand-lg navbar-light ">
        <div class="container-fluid">
            <a class="navbar-brand" href="index.html#homepage">
                <img src="images/formlogo.png" alt="" srcset="">
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="ms-auto navbar-nav">
                    <li class="nav-item">
                        <a class="nav-link"href="advisory.html">Advisory Board</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="air.html">AI and Robotics</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="cs.html">Cyber Security</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="iot.html">Internet of Things</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="Blogs.html">Blogs</a>
                      </li>
                    <li class="nav-item">
                        <a class="nav-link"href="contactus.html">Contact Us</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <div class="main__body">
        <div class="row">
            <div class="text__box col-lg-7">
                <h1>AI and Robotics Center (AIR)</h1>
                <hr>
                <div>
                    The AIR Lab is an initiative brought to reality in VIT APUniversity and its the first
                    of its kind in the country.
                    Set up with the aim of learning about the latest
                    technologies of the field like Deep Learning, Machine
                    Learning and Robotics,
                    the AIR Lab has given students a platform to not only learn about them but
                    work with them to build something unique.
                    The lab makes an ideal
                    technology-rich environment to promote student-driven learning and provides
                    a
                    new approach to learning rather than the customary way.
                    The lab has grown
                    with more students coming in with unique ideas worth working on. With the
                    support of
                    the faculty, the aim is to be a place of harmony for ideas and latest
                    technologies, and make them a
                    reality.
                </div>
            </div>
            <div class="img__box col-lg-5">
                <img src="images/pic4.png" alt="" srcset="">
            </div>

            <div class="text__box col-lg-9">
                <h1>Thrust Areas</h1>
                <hr>
            </div>
            <div class="profile_images col-lg-4">
                <figure><img src="images/pic5.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Artificial Intelligence</figcaption>
                </figure>

            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic6.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Machine Vision</figcaption>
                </figure>

            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic7.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Machine Intelligence
                        and Robotics</figcaption>
                </figure>
            </div>
            <!-- <div class="img__box col-lg-5">
                <img src="images/pic3.png" alt="" srcset="">
            </div> -->
            <div class="text__box col-lg-7">
                <h1>Projects</h1>
                <hr>
            </div>
            <!-- first coursel -->
            <div class="main_slide">
                <!-- Slideshow container -->
                <div class="slideshow-container">
                    <!-- Full-width slides/quotes -->
                    <div class="mySlides">
                        <center><img src="images/pic8.png" alt="" class="coursel_images"></center>
                        <div class="coursel_text">
                            <h4>TARS</h4>
                            <div>T.A.R.S is a quadruped that can walk at any terrain. The
                                main aim of the project is to leverage this technology in 
                                botanical gardens so as to monitor plant health. The other
                                application of it being monitoring condition of the crop.
                                T.A.R.S uses unique creep gait. It is specially 
                                programmed to mimic human and spider movement 
                                simultaneously. The program being quite small is written 
                                to have tars move over 500 steps at one Command.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic2.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4>VISU</h4>
                            <div>VISU(VIT-AP Intelligent super Utility) is a 
                                3D printed robot built from scratch using 
                                minimal design and simple yet sophisticated 
                                electronics. Backed by Arduino and 
                                Raspberry pi and customized so as to make it 
                                modular in terms of design and technology 
                                that expands its range of abilities.
                                The robot comes equipped with Voice and 
                                Face recognition tech. The arms and torso are 
                                powered by high torque Servo motors that 
                                provide enough power to lift a baby. Powered 
                                by over 25 motors, the robot can effortlessly 
                                mimic human movement. Every piece of tech 
                                involved has been hacked, modified and 
                                customized to satisfy constraints that were 
                                once a limitation.
                                This research published in IEEE Consumer 
                                Electronics (Impact Factor: 4.01)
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic3.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4>Vinci X</h4>
                            <div>Vinci X is a body vital monitoring garment that records body vitals and sends 
                                them to cloud and app where Machine Learning algorithms analyze the data 
                                and provide user with a detailed report both in real-time and post-workout.
                                Users can in real-time check their individual muscle activity and ECG along 
                                with other vitals. A visualization shows, graphically, the exerted muscle force 
                                and areas to work on. The same report can be sent to a trainer or a physician 
                                and seek help.The garment has embedded sensors in it.All the sensor values 
                                are transmitted to app and cloud with a cellular based ARC that powers the 
                                suit and is detachable. Customers can use this garment to help them with 
                                working on weak areas and increase workout efficiency by 65%.
                                This research published in IEEE Transactions on Consumer Electronics. 
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic15.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4> Cleo: Smart Glasses to monitor intake of alcohol and number of smokes</h4>
                            <div>Over 60% of people around the globe consume Alcohol and Cigars daily. Many intake them beyond the 
                                permitted limit causing disease such as lung cancer, Liver and kidney Failure. Chain-smokers and Alcoholics 
                                do not have a metric or system that monitors their intake level and alerts the user in case of excess 
                                consumption. To help users monitor their consumption, we introduce Cleo Eyeglasses in this research. Cleo 
                                is a wearable spectacles with mounted camera and single board computer that performs custom trained object 
                                recognition to identify alcoholic beverages and cigarettes. Upon recognition, a log is automatically 
                                maintained in the corresponding mobile application. The user can set the limit or threshold on consumption 
                                levels. If the system detects consumption level beyond the permitted threshold, an alert is sent to the 
                                prescribed medical official for assistance.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic5.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4>  CEREBRO: The Brain Controlled Wheelchair</h4>
                            <div>The project Cerebro is the Mind controlled wheelchair 
                                which controls the direction and motion based on the decision 
                                taken by the user. The mindwave headset is used in the mindcontrolled wheelchair to pick up EEG signals from the brain. 
                                These signals are processed by a microcontroller which in 
                                turn takes a decision regarding the motion and direction of 
                                wheelchair and accordingly drives the motor.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        
                        <div class="coursel_text">
                            <h4>  AI Chatbot: VIT-Assist and VITapian</h4>
                            <div>Vitapian is a chatbot used by VIT AP to answer its most common and general queries. Vitapian lets you 
                                know about the teachers, their cabin numbers along with the intercom details and other miscellaneous.
                                
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        
                        <div class="coursel_text">
                            <h4> OhYes OS</h4>
                            <div>In the world of operating systems linux leads the biggest market share from embedded IoT devices to super 
                                computers.There are plenty of flavours (linux versions) for each use case, but we are yet to have an OS 
                                tailored for AI developers. We bring you the OhYes OS an OS tailored for AI developers ranging from 
                                ninjas to babies. This is custom build operating system developed by our second year student.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4>No Nudity (NN)</h4>
                            <div>The aim of this project is to censor the obscene and indecent images on a website. It is a plugin developed 
                                for accomplishing the same using neural networks. Once the extension is installed, all the images on a 
                                website accessed by the user will be processed and based on the extent of nudity depicted, images will be 
                                removed on the client side.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic9.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4> Coconut Tree Detection
                            </h4>
                            <div>What could possibly be the intention behind knowing the 
                                number of trees in an area? Be it Disaster Management, 
                                calculating the assets of the state, or under advanced 
                                circumstances, the ability to detect the quality of the trees, the 
                                Coconut Detection System is one to look into. Using image 
                                processing to detect coconut trees from aerial views, is an 
                                innovative design which requires object detection models. 
                                During the development of the project, the members also 
                                developed a new object detection model – RetinaNet model. A 
                                combination of Focal Loss and ResNet, this new model 
                                surpassed the R-CNN model, while still being a stage one 
                                detector.
                                The final results of the project were accurate to a point where it could be deployed on a drone and be applied 
                                on live-feed. There is also further scope to better the model. This is a collaborative work with APSAC. This 
                                paper is submitted to Journal of Scientific and Industrial Research.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic4.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4> Project Dante</h4>
                            <div>Project Dante is an e-bike that is equipped with 
                                state of the art object detection and integrated 
                                with application controlled features. 
                                Mechanically, the vehicle can travel over 80 
                                Kms in one single charge.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4>ReMedic
                            </h4>
                            <div>With technology developing, the health sector has been developing too. ReMedic is yet another step towards 
                                faster medical treatment to accident victims. It is an emergency service and aims at shortening the time by 
                                incorporating new-age technologies like drones and health monitoring sensors.
                                In case of an accident, the UID and GPS Coordinates call for the nearest hospital’s assistance by sending 
                                live data and feed using ML Algorithms. The case is then assigned to the available doctor. Machine Learning 
                                is used to analyse the patient’s condition and suggest solutions to the doctor. Medication is loaded into 
                                drones and sent to the accident site for initial treatment while the ambulance is sent to pick the victim up.
                                ReMedic aims at redefining and improving the emergency services and save lives
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic10(1).png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4>  Nirvana</h4>
                            <div>Nirvana is a Retail product classification checkout unit that use state-of-the-art computer vision to identify 
                                products as you drop them in the cart. Also, remove the product from the invoice that is removed from the 
                                cart. All by just using AI. Nirvana helps you in skipping checkout lines with ease and doesn’t waste your 
                                time and energy on waiting in checkout lines. 
                                Scan and Go is the future.
                                
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic11.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4>Whatsapp Chatbot:</h4>
                            <div>VIT-AP Whatsapp chatbot allows students to retrieve their timetable, class 
                                timings, announcements made on Vtop by simply just asking the bot. The bot 
                                leverages state-of-the-art NLP to recognise your simple commands and fetches 
                                data from the DB. Therefore, giving the student On-the-go updates
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <img src="images/airpic13.png" alt="" class="coursel_images">
                        <div class="coursel_text">
                            <h4> Furniture Land</h4>
                            <div>Furniture Land is an Augmented Reality 
                                Application that can be linked with any online 
                                furniture marketplace, bringing in the products 
                                in virtual reality to allow customers pre-plans 
                                the furniture locations at home. The application 
                                also allows user to purchase and place an order 
                                from the cart option in the app
                                
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4>DOWCS: Decentralized Open Web Cryptographic Standard</h4>
                            <div>Security in web services is not well defined and is largely based on measures employed by the organization 
                                providing the service, the effectiveness of which vary greatly depending on the expertise, implementation, 
                                and business motivation. To address the mentioned issue, this research proposes an open standard called 
                                Decentralized Open Web Cryptographic Standard (DOWCS) and reference implementation for 
                                decentralized protection of sensitive data. Services may adhere to the standards, to assure security to the 
                                end-user. Taking OAuth and PGP as reference models, the standard incorporates multiple layers of security 
                                to ensure secrecy of the said data while also decentralizing the key information required to derive the 
                                confidential data from the encrypted format.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4> SimplyMime</h4>
                            <div>SimplyMime is a wholesome gesture recognition system to make life simpler. It combines the power of 
                                Artificial Intelligence of Things (AIoT) to provide a better and faster user experience in the ubiquitous 
                                environment just with the movement of the fingers. The user can control the systems in the integrated 
                                ubiquitous environment just by moving the hands in the air and making gestures just like we have seen in 
                                the movies. A lot of day-to-day activities like moving the mouse, controlling volume, drawing, opening 
                                specific applications, home automations etc., can be much simpler with our SimplyMime. SimplyMime not 
                                only makes this a reality but also follows the user around their room so that every gesture the user makes is 
                                clearly read, and the task is accomplished. The system would track the user movements and a webcam 
                                mounted on to a microcontroller would turn to the user wherever the user is in the room. The user can further 
                                make relevant gestures with their hands and the system will immediately respond. SimplyMime uses face 
                                detection, pose estimation combined with port communication to the microcontroller to achieve this. This 
                                system can be further scaled and used for various other purposes like gaming, Unmanned vehicle control 
                                (e.g.: drones) and other controls etc.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4> iDrone: IoT-Enabled Unmanned Aerial Vehicles for Detecting WildFires using 
                                Convolutional Neural Networks</h4>
                            <div>The rise of global temperatures, over the past few decades, has disrupted the usual balance of nature. As a 
                                result of increasing temperatures, wildfires have destroyed millions of acres of land, thousands of structures, 
                                and homes. The pollution and toxic gases produced by the wildfires are carried out to thousands of miles, 
                                thus threatening the lives all around the world. Most wildfires occur due to anthropogenic factors, which 
                                cannot be predicted solely based on climate conditions. Henceforth, to detect wildfires before escalating, we 
                                propose iDrone, which is a wildfire detection system equipped with an end-to-end CNN image classification 
                                model: XtinguishNet, trained on a wildfire imagery dataset to detect the possible flames or smokes in an 
                                image. In addition, our approach also acquires the weather data and the intensity of the fire. Contrasting with 
                                existing wildfire detection systems, our proposed solution is a fusion of the Internet of Things (IoT) and 
                                Deep Learning, aiming to provide a one-stop solution for all the needs required to minimize the damage 
                                caused by wildfires. When validated and tested using various benchmark datasets, video surveillance, iDrone 
                                acquired a high accuracy of 98.36% with the least computational power.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides">
                        <div class="coursel_text">
                            <h4> Efficientword-Net: An Open Source Hotword Detection Engine based on One-shot 
                                Learning</h4>
                            <div>Voice assistants like Siri, Google Assistant, Alexa etc. are used widely across the globe for home automation, 
                                these require the use of special phrases also known as hotwords to wake it up and perform an action like 
                                “Hey Alexa!”, “Ok Google” and “Hey Siri” etc. These hotwords are detected with lightweight real-time 
                                engines whose purpose is to detect the hotwords uttered by the user. This research presents the design and 
                                implementation of a hotword detection engine based on one-shot learning which detects the hotword uttered 
                                by the user in real-time with just one or few training samples of the hotword. This approach is efficient when 
                                compared to existing implementations because the process of adding a new hotword in the existing systems 
                                requires enormous amounts of positive and negative training samples and the model needs to retrain for 
                                every hotword. This makes the existing implementations inefficient in terms of computation and cost. The 
                                architecture proposed in this research has achieved an accuracy of 96.8%.
                            </div>
                        </div>
                    </div>
                    <!-- Next/prev buttons -->
                    <a class="prev" onclick="plusSlides(-1)">&#10094;</a>
                    <a class="next" onclick="plusSlides(1)">&#10095;</a>
                </div>

                <!-- Dots/bullets/indicators -->
                <div class="dot-container">
                    <span class="dot" onclick="currentSlide(1)"></span>
                    <span class="dot" onclick="currentSlide(2)"></span>
                    <span class="dot" onclick="currentSlide(3)"></span>
                    <span class="dot" onclick="currentSlide(4)"></span>
                    <span class="dot" onclick="currentSlide(5)"></span>
                    <span class="dot" onclick="currentSlide(6)"></span>
                    <span class="dot" onclick="currentSlide(7)"></span>
                    <span class="dot" onclick="currentSlide(8)"></span>
                    <span class="dot" onclick="currentSlide(9)"></span>
                    <span class="dot" onclick="currentSlide(10)"></span>
                    <span class="dot" onclick="currentSlide(11)"></span>
                    <span class="dot" onclick="currentSlide(12)"></span>
                    <span class="dot" onclick="currentSlide(13)"></span>
                    <span class="dot" onclick="currentSlide(14)"></span>
                    <span class="dot" onclick="currentSlide(15)"></span>
                    <span class="dot" onclick="currentSlide(16)"></span>
                    <span class="dot" onclick="currentSlide(17)"></span>
                    
                </div>
            </div>
            <!-- end of first coursel -->
            <!-- <div class="text__box col-lg-7">
                <h1>Patents Published</h1>
                <hr>
            </div> -->
            <!-- second coursel -->
            <!-- <div class="main_slide">
                <div class="slideshow-container">
                    <div class="mySlides2">
                        <center><img src="images/pic9.png" alt="" class="coursel_images"></center>
                        <div class="coursel_text2">
                            <h4>Precise URL Phishing Detection Using Neural
                                Networks and Genetic Algorithms</h4>
                            <div> <ul>
                                <li>Aman Rangapur, SCOPE </li>
                                <li>Dr. Ajith Jubilson E, SCOPE </li>
                                <li>Dhanavanthini P, SCOPE </li>
                                <li>Dr. Sibi Chakkaravarthy S, SCOPE </li>
                            </ul>
                            </div>
                        </div>
                    </div>
                    <div class="mySlides2">
                        <img src="images/pic8.png" alt="" class="coursel_images">
                        <div class="coursel_text2">
                            <h4>TARS 2</h4>
                            <div>VISU(VIT-AP Intelligent super Utility) is a
                                3D printed robot built from scratch
                                using
                                minimal design and simple yet
                                sophisticated electronics. Backed by

                                Arduino and Raspberry pi and
                                customized so as to make it modular in
                                terms
                                of design and technology that
                                expands its range of abilities.
                                The robot comes
                                equipped with Voice
                                and Face recognition tech. The arms and
                                torso are
                                powered by high torque Servo
                                motors that provide enough power to lift
                                a
                                baby. Powered by over 25 motors, the
                                robot can effortlessly mimic human

                                movement. Every piece of tech involved
                                has been hacked, modified and

                                customized to satisfy constraints that
                                were once a limitation.
                            </div>
                        </div>
                    </div>
                    <div class="mySlides2">
                        <img src="images/pic8.png" alt="" class="coursel_images">
                        <div class="coursel_text2">
                            <h4>TARS 3</h4>
                            <div>VISU(VIT-AP Intelligent super Utility) is a
                                3D printed robot built from scratch
                                using
                                minimal design and simple yet
                                sophisticated electronics. Backed by

                                Arduino and Raspberry pi and
                                customized so as to make it modular in
                                terms
                                of design and technology that
                                expands its range of abilities.
                                The robot comes
                                equipped with Voice
                                and Face recognition tech. The arms and
                                torso are
                                powered by high torque Servo
                                motors that provide enough power to lift
                                a
                                baby. Powered by over 25 motors, the
                                robot can effortlessly mimic human

                                movement. Every piece of tech involved
                                has been hacked, modified and

                                customized to satisfy constraints that
                                were once a limitation.
                            </div>
                        </div>
                    </div>
                    <a class="prev" onclick="plusSlides2(-1)">&#10094;</a>
                    <a class="next" onclick="plusSlides2(1)">&#10095;</a>
                </div>

    
                <div class="dot-container">
                    <span class="dot2" onclick="currentSlide2(1)"></span>
                    <span class="dot2" onclick="currentSlide2(2)"></span>
                    <span class="dot2" onclick="currentSlide2(3)"></span>
                </div>
            </div> -->
            <!-- end of second coursel -->
            <div class="text__box col-lg-9">
                <h1>Members</h1>
                <hr>
            </div>
            <div class="profile_images col-lg-4">
                <figure><img src="images/pic10.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Hari Seetha</figcaption>
                    <figcaption style="color:#650010">Director</figcaption>
                </figure>

            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic11.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Sibi Chakkaravarthy</figcaption>
                    <figcaption style="color:#650010">Coordinator</figcaption>
                </figure>

            </div>

       
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic15.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Sumathi D</figcaption>
                </figure>
            </div>

            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic17.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Subhashish Mahapatra</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic18.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Sukanta Nayak</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic19.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Ambuj Sharma</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic20.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Chandan Vishwas</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic21.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Manomita Chakraborty</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic22.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Reeja S R</figcaption>
                </figure>
            </div>


            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic25.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Mehfooza Munavar Basha</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic26.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Divya Meena Sundaram</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic27.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr.Srinivas Battula</figcaption>
                </figure>
            </div>



            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic31.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Sheela J</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic32.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Kuppusamy P</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic33.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Venkata Lakshmi Dasari</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic34.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Afzal Hussain Shahid</figcaption>
                </figure>
            </div>
            <div class="profile_images col-lg-4">
                <figure>
                    <img src="images/pic35.png" alt="" class="images_subject">
                    <figcaption class="image_caption">Dr. Monali Bordoloi</figcaption>
                </figure>
            </div>

        </div>
    </div>
    <footer class="footer__wrapper">
        <div class="footer__inner">
            <img src="images/formlogo.png" alt="" srcset="">
            <h1>Center of Excellence</h1>
            <div class="row mx-auto">
                <div style="width: fit-content;"><a href="index.html" class="nav-link">Home</a></div>
            <div style="width: fit-content;"><a href="air.html" class="nav-link">AIR Center</a></div>
            <div style="width: fit-content;"><a href="cs.html" class="nav-link">Cyber Security</a></div>
            <div style="width: fit-content;"><a href="iot.html" class="nav-link">IOT Center</a></div>
            <div style="width: fit-content;"><a href="contactus.html" class="nav-link">Contact</a></div>
            </div>
            <div class="row mx-auto">
                <div style="width: fit-content;"><a href="" class="social__link"><i class='bx bxl-facebook'></i></a>
                </div>
                <div style="width: fit-content;"><a href="" class="social__link"><i class='bx bxl-twitter'></i></a>
                </div>
                <div style="width: fit-content;"><a href="" class="social__link"><i class='bx bxl-instagram'></i></a>
                </div>
            </div>
            <div class="mx-auto copyright__text">Copyright © VIT-AP COE 2022. All rights reserved.</div>
        </div>
    </footer>
</body>
<script>
    var slideIndex = 1;
    showSlides(slideIndex);

    function plusSlides(n) {
        showSlides(slideIndex += n);
    }

    function currentSlide(n) {
        showSlides(slideIndex = n);
    }

    function showSlides(n) {
        var i;
        var slides = document.getElementsByClassName("mySlides");
        var dots = document.getElementsByClassName("dot");
        if (n > slides.length) { slideIndex = 1 }
        if (n < 1) { slideIndex = slides.length }
        for (i = 0; i < slides.length; i++) {
            slides[i].style.display = "none";
        }
        for (i = 0; i < dots.length; i++) {
            dots[i].className = dots[i].className.replace(" active", "");
        }
        slides[slideIndex - 1].style.display = "flex";
        dots[slideIndex - 1].className += " active";
    }
    // second
    var slideIndex2 = 1;
    showSlides2(slideIndex2);

    function plusSlides2(n) {
        showSlides2(slideIndex2 += n);
    }

    function currentSlide2(n) {
        showSlides2(slideIndex2 = n);
    }

    function showSlides2(n) {
        var i;
        var slides = document.getElementsByClassName("mySlides2");
        var dots = document.getElementsByClassName("dot2");
        if (n > slides.length) { slideIndex2 = 1 }
        if (n < 1) { slideIndex2 = slides.length }
        for (i = 0; i < slides.length; i++) {
            slides[i].style.display = "none";
        }
        for (i = 0; i < dots.length; i++) {
            dots[i].className = dots[i].className.replace(" active", "");
        }
        slides[slideIndex2 - 1].style.display = "flex";
        dots[slideIndex2 - 1].className += " active";
    }
</script>
<script src="js/jquery-1.11.3.min.js"></script>
<script src="js/bootstrap.bundle.min.js"></script>

</html>